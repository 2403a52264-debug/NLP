{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJzc89t8gFrxDzVIQyIZIo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2403a52264-debug/NLP/blob/main/NLP_LAB_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "##  CANVAS ASSIGNMENT\n",
        "\n"
      ],
      "metadata": {
        "id": "Kg1v6or188kB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Firstly we were loading medical text corpus data"
      ],
      "metadata": {
        "id": "5WoTXyZLbSXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "medical_corpus = \"\"\"\n",
        "Abstract 1: Patients with diabetes mellitus type 2 (DM2) often experience cardiovascular complications including myocardial infarction and stroke. Glycemic control through insulin therapy and oral hypoglycemics remains challenging.\n",
        "\n",
        "Abstract 2: Acute coronary syndrome (ACS) presents with chest pain, dyspnea, and diaphoresis. Troponin levels and ECG changes guide thrombolytic therapy and percutaneous coronary intervention (PCI).\n",
        "\n",
        "Abstract 3: Chronic kidney disease (CKD) progression correlates with proteinuria levels and glomerular filtration rate (GFR). Renin-angiotensin-aldosterone system (RAAS) inhibitors slow disease advancement.\n",
        "\n",
        "Abstract 4: Alzheimer's disease (AD) pathology involves amyloid-beta plaques and tau tangles. Cholinesterase inhibitors provide symptomatic relief but disease-modifying therapies remain elusive.\n",
        "\n",
        "Abstract 5: Sepsis management requires early recognition through qSOFA criteria and prompt broad-spectrum antibiotics. Lactate clearance monitoring guides resuscitation efforts.\n",
        "\n",
        "Abstract 6: Rheumatoid arthritis (RA) treatment escalates from methotrexate monotherapy to biologic DMARDs including TNF inhibitors when disease activity persists.\n",
        "\n",
        "Abstract 7: Colorectal cancer screening via fecal immunochemical testing (FIT) detects occult blood indicating colonoscopy for polyp resection and early-stage intervention.\n",
        "\"\"\"\n",
        "\n",
        "medical_corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "iO2uAIW6A1a8",
        "outputId": "f999c3c0-84d8-41a6-efb3-9869d2816e40"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nAbstract 1: Patients with diabetes mellitus type 2 (DM2) often experience cardiovascular complications including myocardial infarction and stroke. Glycemic control through insulin therapy and oral hypoglycemics remains challenging.\\n\\nAbstract 2: Acute coronary syndrome (ACS) presents with chest pain, dyspnea, and diaphoresis. Troponin levels and ECG changes guide thrombolytic therapy and percutaneous coronary intervention (PCI).\\n\\nAbstract 3: Chronic kidney disease (CKD) progression correlates with proteinuria levels and glomerular filtration rate (GFR). Renin-angiotensin-aldosterone system (RAAS) inhibitors slow disease advancement.\\n\\nAbstract 4: Alzheimer's disease (AD) pathology involves amyloid-beta plaques and tau tangles. Cholinesterase inhibitors provide symptomatic relief but disease-modifying therapies remain elusive.\\n\\nAbstract 5: Sepsis management requires early recognition through qSOFA criteria and prompt broad-spectrum antibiotics. Lactate clearance monitoring guides resuscitation efforts.\\n\\nAbstract 6: Rheumatoid arthritis (RA) treatment escalates from methotrexate monotherapy to biologic DMARDs including TNF inhibitors when disease activity persists.\\n\\nAbstract 7: Colorectal cancer screening via fecal immunochemical testing (FIT) detects occult blood indicating colonoscopy for polyp resection and early-stage intervention.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Here we imported nltk and spacy modules and also word tokenize and sentence tokenize"
      ],
      "metadata": {
        "id": "6BlrP30sbcgb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_Nf7SFhb7BB2",
        "outputId": "d61f0864-01c6-4f0f-9a3d-5a828a9eb1fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import spacy\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# we printed the word tokenize words"
      ],
      "metadata": {
        "id": "xd3fCtmDbt1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize(medical_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "oKZHYi4wBVtZ",
        "outputId": "8743cc3d-7d6a-47f4-e50c-0d5bc30fa8c3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Abstract',\n",
              " '1',\n",
              " ':',\n",
              " 'Patients',\n",
              " 'with',\n",
              " 'diabetes',\n",
              " 'mellitus',\n",
              " 'type',\n",
              " '2',\n",
              " '(',\n",
              " 'DM2',\n",
              " ')',\n",
              " 'often',\n",
              " 'experience',\n",
              " 'cardiovascular',\n",
              " 'complications',\n",
              " 'including',\n",
              " 'myocardial',\n",
              " 'infarction',\n",
              " 'and',\n",
              " 'stroke',\n",
              " '.',\n",
              " 'Glycemic',\n",
              " 'control',\n",
              " 'through',\n",
              " 'insulin',\n",
              " 'therapy',\n",
              " 'and',\n",
              " 'oral',\n",
              " 'hypoglycemics',\n",
              " 'remains',\n",
              " 'challenging',\n",
              " '.',\n",
              " 'Abstract',\n",
              " '2',\n",
              " ':',\n",
              " 'Acute',\n",
              " 'coronary',\n",
              " 'syndrome',\n",
              " '(',\n",
              " 'ACS',\n",
              " ')',\n",
              " 'presents',\n",
              " 'with',\n",
              " 'chest',\n",
              " 'pain',\n",
              " ',',\n",
              " 'dyspnea',\n",
              " ',',\n",
              " 'and',\n",
              " 'diaphoresis',\n",
              " '.',\n",
              " 'Troponin',\n",
              " 'levels',\n",
              " 'and',\n",
              " 'ECG',\n",
              " 'changes',\n",
              " 'guide',\n",
              " 'thrombolytic',\n",
              " 'therapy',\n",
              " 'and',\n",
              " 'percutaneous',\n",
              " 'coronary',\n",
              " 'intervention',\n",
              " '(',\n",
              " 'PCI',\n",
              " ')',\n",
              " '.',\n",
              " 'Abstract',\n",
              " '3',\n",
              " ':',\n",
              " 'Chronic',\n",
              " 'kidney',\n",
              " 'disease',\n",
              " '(',\n",
              " 'CKD',\n",
              " ')',\n",
              " 'progression',\n",
              " 'correlates',\n",
              " 'with',\n",
              " 'proteinuria',\n",
              " 'levels',\n",
              " 'and',\n",
              " 'glomerular',\n",
              " 'filtration',\n",
              " 'rate',\n",
              " '(',\n",
              " 'GFR',\n",
              " ')',\n",
              " '.',\n",
              " 'Renin-angiotensin-aldosterone',\n",
              " 'system',\n",
              " '(',\n",
              " 'RAAS',\n",
              " ')',\n",
              " 'inhibitors',\n",
              " 'slow',\n",
              " 'disease',\n",
              " 'advancement',\n",
              " '.',\n",
              " 'Abstract',\n",
              " '4',\n",
              " ':',\n",
              " 'Alzheimer',\n",
              " \"'s\",\n",
              " 'disease',\n",
              " '(',\n",
              " 'AD',\n",
              " ')',\n",
              " 'pathology',\n",
              " 'involves',\n",
              " 'amyloid-beta',\n",
              " 'plaques',\n",
              " 'and',\n",
              " 'tau',\n",
              " 'tangles',\n",
              " '.',\n",
              " 'Cholinesterase',\n",
              " 'inhibitors',\n",
              " 'provide',\n",
              " 'symptomatic',\n",
              " 'relief',\n",
              " 'but',\n",
              " 'disease-modifying',\n",
              " 'therapies',\n",
              " 'remain',\n",
              " 'elusive',\n",
              " '.',\n",
              " 'Abstract',\n",
              " '5',\n",
              " ':',\n",
              " 'Sepsis',\n",
              " 'management',\n",
              " 'requires',\n",
              " 'early',\n",
              " 'recognition',\n",
              " 'through',\n",
              " 'qSOFA',\n",
              " 'criteria',\n",
              " 'and',\n",
              " 'prompt',\n",
              " 'broad-spectrum',\n",
              " 'antibiotics',\n",
              " '.',\n",
              " 'Lactate',\n",
              " 'clearance',\n",
              " 'monitoring',\n",
              " 'guides',\n",
              " 'resuscitation',\n",
              " 'efforts',\n",
              " '.',\n",
              " 'Abstract',\n",
              " '6',\n",
              " ':',\n",
              " 'Rheumatoid',\n",
              " 'arthritis',\n",
              " '(',\n",
              " 'RA',\n",
              " ')',\n",
              " 'treatment',\n",
              " 'escalates',\n",
              " 'from',\n",
              " 'methotrexate',\n",
              " 'monotherapy',\n",
              " 'to',\n",
              " 'biologic',\n",
              " 'DMARDs',\n",
              " 'including',\n",
              " 'TNF',\n",
              " 'inhibitors',\n",
              " 'when',\n",
              " 'disease',\n",
              " 'activity',\n",
              " 'persists',\n",
              " '.',\n",
              " 'Abstract',\n",
              " '7',\n",
              " ':',\n",
              " 'Colorectal',\n",
              " 'cancer',\n",
              " 'screening',\n",
              " 'via',\n",
              " 'fecal',\n",
              " 'immunochemical',\n",
              " 'testing',\n",
              " '(',\n",
              " 'FIT',\n",
              " ')',\n",
              " 'detects',\n",
              " 'occult',\n",
              " 'blood',\n",
              " 'indicating',\n",
              " 'colonoscopy',\n",
              " 'for',\n",
              " 'polyp',\n",
              " 'resection',\n",
              " 'and',\n",
              " 'early-stage',\n",
              " 'intervention',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# we printed the sentence tokenize words"
      ],
      "metadata": {
        "id": "glf_zqFKb7Ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokenize(medical_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9smDvMsib9jy",
        "outputId": "bf31ba3c-3368-4936-8804-da550d2dbc31"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\nAbstract 1: Patients with diabetes mellitus type 2 (DM2) often experience cardiovascular complications including myocardial infarction and stroke.',\n",
              " 'Glycemic control through insulin therapy and oral hypoglycemics remains challenging.',\n",
              " 'Abstract 2: Acute coronary syndrome (ACS) presents with chest pain, dyspnea, and diaphoresis.',\n",
              " 'Troponin levels and ECG changes guide thrombolytic therapy and percutaneous coronary intervention (PCI).',\n",
              " 'Abstract 3: Chronic kidney disease (CKD) progression correlates with proteinuria levels and glomerular filtration rate (GFR).',\n",
              " 'Renin-angiotensin-aldosterone system (RAAS) inhibitors slow disease advancement.',\n",
              " \"Abstract 4: Alzheimer's disease (AD) pathology involves amyloid-beta plaques and tau tangles.\",\n",
              " 'Cholinesterase inhibitors provide symptomatic relief but disease-modifying therapies remain elusive.',\n",
              " 'Abstract 5: Sepsis management requires early recognition through qSOFA criteria and prompt broad-spectrum antibiotics.',\n",
              " 'Lactate clearance monitoring guides resuscitation efforts.',\n",
              " 'Abstract 6: Rheumatoid arthritis (RA) treatment escalates from methotrexate monotherapy to biologic DMARDs including TNF inhibitors when disease activity persists.',\n",
              " 'Abstract 7: Colorectal cancer screening via fecal immunochemical testing (FIT) detects occult blood indicating colonoscopy for polyp resection and early-stage intervention.']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now we were importing stopwords"
      ],
      "metadata": {
        "id": "ROa3dTvtcCuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zifUZbBDB_3_",
        "outputId": "0dda3bbf-f482-432d-f0e1-e32e06ce4f4e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Here we have put tokenized words into word_in_quote variable"
      ],
      "metadata": {
        "id": "jWZ-elFZcLik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_in_quote = word_tokenize(medical_corpus)\n",
        "word_in_quote"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "a1kNmNJ7C_YL",
        "outputId": "44525edd-3a65-45c6-f0d1-3328d060a7a2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Abstract',\n",
              " '1',\n",
              " ':',\n",
              " 'Patients',\n",
              " 'with',\n",
              " 'diabetes',\n",
              " 'mellitus',\n",
              " 'type',\n",
              " '2',\n",
              " '(',\n",
              " 'DM2',\n",
              " ')',\n",
              " 'often',\n",
              " 'experience',\n",
              " 'cardiovascular',\n",
              " 'complications',\n",
              " 'including',\n",
              " 'myocardial',\n",
              " 'infarction',\n",
              " 'and',\n",
              " 'stroke',\n",
              " '.',\n",
              " 'Glycemic',\n",
              " 'control',\n",
              " 'through',\n",
              " 'insulin',\n",
              " 'therapy',\n",
              " 'and',\n",
              " 'oral',\n",
              " 'hypoglycemics',\n",
              " 'remains',\n",
              " 'challenging',\n",
              " '.',\n",
              " 'Abstract',\n",
              " '2',\n",
              " ':',\n",
              " 'Acute',\n",
              " 'coronary',\n",
              " 'syndrome',\n",
              " '(',\n",
              " 'ACS',\n",
              " ')',\n",
              " 'presents',\n",
              " 'with',\n",
              " 'chest',\n",
              " 'pain',\n",
              " ',',\n",
              " 'dyspnea',\n",
              " ',',\n",
              " 'and',\n",
              " 'diaphoresis',\n",
              " '.',\n",
              " 'Troponin',\n",
              " 'levels',\n",
              " 'and',\n",
              " 'ECG',\n",
              " 'changes',\n",
              " 'guide',\n",
              " 'thrombolytic',\n",
              " 'therapy',\n",
              " 'and',\n",
              " 'percutaneous',\n",
              " 'coronary',\n",
              " 'intervention',\n",
              " '(',\n",
              " 'PCI',\n",
              " ')',\n",
              " '.',\n",
              " 'Abstract',\n",
              " '3',\n",
              " ':',\n",
              " 'Chronic',\n",
              " 'kidney',\n",
              " 'disease',\n",
              " '(',\n",
              " 'CKD',\n",
              " ')',\n",
              " 'progression',\n",
              " 'correlates',\n",
              " 'with',\n",
              " 'proteinuria',\n",
              " 'levels',\n",
              " 'and',\n",
              " 'glomerular',\n",
              " 'filtration',\n",
              " 'rate',\n",
              " '(',\n",
              " 'GFR',\n",
              " ')',\n",
              " '.',\n",
              " 'Renin-angiotensin-aldosterone',\n",
              " 'system',\n",
              " '(',\n",
              " 'RAAS',\n",
              " ')',\n",
              " 'inhibitors',\n",
              " 'slow',\n",
              " 'disease',\n",
              " 'advancement',\n",
              " '.',\n",
              " 'Abstract',\n",
              " '4',\n",
              " ':',\n",
              " 'Alzheimer',\n",
              " \"'s\",\n",
              " 'disease',\n",
              " '(',\n",
              " 'AD',\n",
              " ')',\n",
              " 'pathology',\n",
              " 'involves',\n",
              " 'amyloid-beta',\n",
              " 'plaques',\n",
              " 'and',\n",
              " 'tau',\n",
              " 'tangles',\n",
              " '.',\n",
              " 'Cholinesterase',\n",
              " 'inhibitors',\n",
              " 'provide',\n",
              " 'symptomatic',\n",
              " 'relief',\n",
              " 'but',\n",
              " 'disease-modifying',\n",
              " 'therapies',\n",
              " 'remain',\n",
              " 'elusive',\n",
              " '.',\n",
              " 'Abstract',\n",
              " '5',\n",
              " ':',\n",
              " 'Sepsis',\n",
              " 'management',\n",
              " 'requires',\n",
              " 'early',\n",
              " 'recognition',\n",
              " 'through',\n",
              " 'qSOFA',\n",
              " 'criteria',\n",
              " 'and',\n",
              " 'prompt',\n",
              " 'broad-spectrum',\n",
              " 'antibiotics',\n",
              " '.',\n",
              " 'Lactate',\n",
              " 'clearance',\n",
              " 'monitoring',\n",
              " 'guides',\n",
              " 'resuscitation',\n",
              " 'efforts',\n",
              " '.',\n",
              " 'Abstract',\n",
              " '6',\n",
              " ':',\n",
              " 'Rheumatoid',\n",
              " 'arthritis',\n",
              " '(',\n",
              " 'RA',\n",
              " ')',\n",
              " 'treatment',\n",
              " 'escalates',\n",
              " 'from',\n",
              " 'methotrexate',\n",
              " 'monotherapy',\n",
              " 'to',\n",
              " 'biologic',\n",
              " 'DMARDs',\n",
              " 'including',\n",
              " 'TNF',\n",
              " 'inhibitors',\n",
              " 'when',\n",
              " 'disease',\n",
              " 'activity',\n",
              " 'persists',\n",
              " '.',\n",
              " 'Abstract',\n",
              " '7',\n",
              " ':',\n",
              " 'Colorectal',\n",
              " 'cancer',\n",
              " 'screening',\n",
              " 'via',\n",
              " 'fecal',\n",
              " 'immunochemical',\n",
              " 'testing',\n",
              " '(',\n",
              " 'FIT',\n",
              " ')',\n",
              " 'detects',\n",
              " 'occult',\n",
              " 'blood',\n",
              " 'indicating',\n",
              " 'colonoscopy',\n",
              " 'for',\n",
              " 'polyp',\n",
              " 'resection',\n",
              " 'and',\n",
              " 'early-stage',\n",
              " 'intervention',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Here we were removing the stop words from our  text data and inserting into new variable"
      ],
      "metadata": {
        "id": "qa3bxb_pcXJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "filtered_list = []\n",
        "for word in word_in_quote:\n",
        "  if word.casefold() not in stop_words:\n",
        "    filtered_list.append(word)\n",
        "filtered_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "iAXJvtiUDLmA",
        "outputId": "78699f2b-bcdd-4efb-ce22-4781080235f3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Abstract',\n",
              " '1',\n",
              " ':',\n",
              " 'Patients',\n",
              " 'diabetes',\n",
              " 'mellitus',\n",
              " 'type',\n",
              " '2',\n",
              " '(',\n",
              " 'DM2',\n",
              " ')',\n",
              " 'often',\n",
              " 'experience',\n",
              " 'cardiovascular',\n",
              " 'complications',\n",
              " 'including',\n",
              " 'myocardial',\n",
              " 'infarction',\n",
              " 'stroke',\n",
              " '.',\n",
              " 'Glycemic',\n",
              " 'control',\n",
              " 'insulin',\n",
              " 'therapy',\n",
              " 'oral',\n",
              " 'hypoglycemics',\n",
              " 'remains',\n",
              " 'challenging',\n",
              " '.',\n",
              " 'Abstract',\n",
              " '2',\n",
              " ':',\n",
              " 'Acute',\n",
              " 'coronary',\n",
              " 'syndrome',\n",
              " '(',\n",
              " 'ACS',\n",
              " ')',\n",
              " 'presents',\n",
              " 'chest',\n",
              " 'pain',\n",
              " ',',\n",
              " 'dyspnea',\n",
              " ',',\n",
              " 'diaphoresis',\n",
              " '.',\n",
              " 'Troponin',\n",
              " 'levels',\n",
              " 'ECG',\n",
              " 'changes',\n",
              " 'guide',\n",
              " 'thrombolytic',\n",
              " 'therapy',\n",
              " 'percutaneous',\n",
              " 'coronary',\n",
              " 'intervention',\n",
              " '(',\n",
              " 'PCI',\n",
              " ')',\n",
              " '.',\n",
              " 'Abstract',\n",
              " '3',\n",
              " ':',\n",
              " 'Chronic',\n",
              " 'kidney',\n",
              " 'disease',\n",
              " '(',\n",
              " 'CKD',\n",
              " ')',\n",
              " 'progression',\n",
              " 'correlates',\n",
              " 'proteinuria',\n",
              " 'levels',\n",
              " 'glomerular',\n",
              " 'filtration',\n",
              " 'rate',\n",
              " '(',\n",
              " 'GFR',\n",
              " ')',\n",
              " '.',\n",
              " 'Renin-angiotensin-aldosterone',\n",
              " 'system',\n",
              " '(',\n",
              " 'RAAS',\n",
              " ')',\n",
              " 'inhibitors',\n",
              " 'slow',\n",
              " 'disease',\n",
              " 'advancement',\n",
              " '.',\n",
              " 'Abstract',\n",
              " '4',\n",
              " ':',\n",
              " 'Alzheimer',\n",
              " \"'s\",\n",
              " 'disease',\n",
              " '(',\n",
              " 'AD',\n",
              " ')',\n",
              " 'pathology',\n",
              " 'involves',\n",
              " 'amyloid-beta',\n",
              " 'plaques',\n",
              " 'tau',\n",
              " 'tangles',\n",
              " '.',\n",
              " 'Cholinesterase',\n",
              " 'inhibitors',\n",
              " 'provide',\n",
              " 'symptomatic',\n",
              " 'relief',\n",
              " 'disease-modifying',\n",
              " 'therapies',\n",
              " 'remain',\n",
              " 'elusive',\n",
              " '.',\n",
              " 'Abstract',\n",
              " '5',\n",
              " ':',\n",
              " 'Sepsis',\n",
              " 'management',\n",
              " 'requires',\n",
              " 'early',\n",
              " 'recognition',\n",
              " 'qSOFA',\n",
              " 'criteria',\n",
              " 'prompt',\n",
              " 'broad-spectrum',\n",
              " 'antibiotics',\n",
              " '.',\n",
              " 'Lactate',\n",
              " 'clearance',\n",
              " 'monitoring',\n",
              " 'guides',\n",
              " 'resuscitation',\n",
              " 'efforts',\n",
              " '.',\n",
              " 'Abstract',\n",
              " '6',\n",
              " ':',\n",
              " 'Rheumatoid',\n",
              " 'arthritis',\n",
              " '(',\n",
              " 'RA',\n",
              " ')',\n",
              " 'treatment',\n",
              " 'escalates',\n",
              " 'methotrexate',\n",
              " 'monotherapy',\n",
              " 'biologic',\n",
              " 'DMARDs',\n",
              " 'including',\n",
              " 'TNF',\n",
              " 'inhibitors',\n",
              " 'disease',\n",
              " 'activity',\n",
              " 'persists',\n",
              " '.',\n",
              " 'Abstract',\n",
              " '7',\n",
              " ':',\n",
              " 'Colorectal',\n",
              " 'cancer',\n",
              " 'screening',\n",
              " 'via',\n",
              " 'fecal',\n",
              " 'immunochemical',\n",
              " 'testing',\n",
              " '(',\n",
              " 'FIT',\n",
              " ')',\n",
              " 'detects',\n",
              " 'occult',\n",
              " 'blood',\n",
              " 'indicating',\n",
              " 'colonoscopy',\n",
              " 'polyp',\n",
              " 'resection',\n",
              " 'early-stage',\n",
              " 'intervention',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Here we done **stemming** for the tokenized words"
      ],
      "metadata": {
        "id": "50e08EdI4Vx5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## here we used porter stemmer"
      ],
      "metadata": {
        "id": "1lg45h2w6mcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "ps = PorterStemmer()\n",
        "words = word_tokenize(medical_corpus)\n",
        "stemmed_words = [ps.stem(word) for word in words]\n",
        "stemmed_words\n"
      ],
      "metadata": {
        "id": "AHuG_OOf8LXk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d7bf0bcd-f01b-4e7c-9c2f-8463fe68eb02"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abstract',\n",
              " '1',\n",
              " ':',\n",
              " 'patient',\n",
              " 'with',\n",
              " 'diabet',\n",
              " 'mellitu',\n",
              " 'type',\n",
              " '2',\n",
              " '(',\n",
              " 'dm2',\n",
              " ')',\n",
              " 'often',\n",
              " 'experi',\n",
              " 'cardiovascular',\n",
              " 'complic',\n",
              " 'includ',\n",
              " 'myocardi',\n",
              " 'infarct',\n",
              " 'and',\n",
              " 'stroke',\n",
              " '.',\n",
              " 'glycem',\n",
              " 'control',\n",
              " 'through',\n",
              " 'insulin',\n",
              " 'therapi',\n",
              " 'and',\n",
              " 'oral',\n",
              " 'hypoglycem',\n",
              " 'remain',\n",
              " 'challeng',\n",
              " '.',\n",
              " 'abstract',\n",
              " '2',\n",
              " ':',\n",
              " 'acut',\n",
              " 'coronari',\n",
              " 'syndrom',\n",
              " '(',\n",
              " 'ac',\n",
              " ')',\n",
              " 'present',\n",
              " 'with',\n",
              " 'chest',\n",
              " 'pain',\n",
              " ',',\n",
              " 'dyspnea',\n",
              " ',',\n",
              " 'and',\n",
              " 'diaphoresi',\n",
              " '.',\n",
              " 'troponin',\n",
              " 'level',\n",
              " 'and',\n",
              " 'ecg',\n",
              " 'chang',\n",
              " 'guid',\n",
              " 'thrombolyt',\n",
              " 'therapi',\n",
              " 'and',\n",
              " 'percutan',\n",
              " 'coronari',\n",
              " 'intervent',\n",
              " '(',\n",
              " 'pci',\n",
              " ')',\n",
              " '.',\n",
              " 'abstract',\n",
              " '3',\n",
              " ':',\n",
              " 'chronic',\n",
              " 'kidney',\n",
              " 'diseas',\n",
              " '(',\n",
              " 'ckd',\n",
              " ')',\n",
              " 'progress',\n",
              " 'correl',\n",
              " 'with',\n",
              " 'proteinuria',\n",
              " 'level',\n",
              " 'and',\n",
              " 'glomerular',\n",
              " 'filtrat',\n",
              " 'rate',\n",
              " '(',\n",
              " 'gfr',\n",
              " ')',\n",
              " '.',\n",
              " 'renin-angiotensin-aldosteron',\n",
              " 'system',\n",
              " '(',\n",
              " 'raa',\n",
              " ')',\n",
              " 'inhibitor',\n",
              " 'slow',\n",
              " 'diseas',\n",
              " 'advanc',\n",
              " '.',\n",
              " 'abstract',\n",
              " '4',\n",
              " ':',\n",
              " 'alzheim',\n",
              " \"'s\",\n",
              " 'diseas',\n",
              " '(',\n",
              " 'ad',\n",
              " ')',\n",
              " 'patholog',\n",
              " 'involv',\n",
              " 'amyloid-beta',\n",
              " 'plaqu',\n",
              " 'and',\n",
              " 'tau',\n",
              " 'tangl',\n",
              " '.',\n",
              " 'cholinesteras',\n",
              " 'inhibitor',\n",
              " 'provid',\n",
              " 'symptomat',\n",
              " 'relief',\n",
              " 'but',\n",
              " 'disease-modifi',\n",
              " 'therapi',\n",
              " 'remain',\n",
              " 'elus',\n",
              " '.',\n",
              " 'abstract',\n",
              " '5',\n",
              " ':',\n",
              " 'sepsi',\n",
              " 'manag',\n",
              " 'requir',\n",
              " 'earli',\n",
              " 'recognit',\n",
              " 'through',\n",
              " 'qsofa',\n",
              " 'criteria',\n",
              " 'and',\n",
              " 'prompt',\n",
              " 'broad-spectrum',\n",
              " 'antibiot',\n",
              " '.',\n",
              " 'lactat',\n",
              " 'clearanc',\n",
              " 'monitor',\n",
              " 'guid',\n",
              " 'resuscit',\n",
              " 'effort',\n",
              " '.',\n",
              " 'abstract',\n",
              " '6',\n",
              " ':',\n",
              " 'rheumatoid',\n",
              " 'arthriti',\n",
              " '(',\n",
              " 'ra',\n",
              " ')',\n",
              " 'treatment',\n",
              " 'escal',\n",
              " 'from',\n",
              " 'methotrex',\n",
              " 'monotherapi',\n",
              " 'to',\n",
              " 'biolog',\n",
              " 'dmard',\n",
              " 'includ',\n",
              " 'tnf',\n",
              " 'inhibitor',\n",
              " 'when',\n",
              " 'diseas',\n",
              " 'activ',\n",
              " 'persist',\n",
              " '.',\n",
              " 'abstract',\n",
              " '7',\n",
              " ':',\n",
              " 'colorect',\n",
              " 'cancer',\n",
              " 'screen',\n",
              " 'via',\n",
              " 'fecal',\n",
              " 'immunochem',\n",
              " 'test',\n",
              " '(',\n",
              " 'fit',\n",
              " ')',\n",
              " 'detect',\n",
              " 'occult',\n",
              " 'blood',\n",
              " 'indic',\n",
              " 'colonoscopi',\n",
              " 'for',\n",
              " 'polyp',\n",
              " 'resect',\n",
              " 'and',\n",
              " 'early-stag',\n",
              " 'intervent',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Snowball stemmer"
      ],
      "metadata": {
        "id": "qh_fgs6k6wjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "snowball = SnowballStemmer(language='english')\n",
        "words = word_tokenize(medical_corpus)\n",
        "for word in words:\n",
        "  print(word,\"-->\",snowball.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lUTgG13C61GH",
        "outputId": "628a96d6-2a6e-43d3-b71f-dbec0e29fa69"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Abstract --> abstract\n",
            "1 --> 1\n",
            ": --> :\n",
            "Patients --> patient\n",
            "with --> with\n",
            "diabetes --> diabet\n",
            "mellitus --> mellitus\n",
            "type --> type\n",
            "2 --> 2\n",
            "( --> (\n",
            "DM2 --> dm2\n",
            ") --> )\n",
            "often --> often\n",
            "experience --> experi\n",
            "cardiovascular --> cardiovascular\n",
            "complications --> complic\n",
            "including --> includ\n",
            "myocardial --> myocardi\n",
            "infarction --> infarct\n",
            "and --> and\n",
            "stroke --> stroke\n",
            ". --> .\n",
            "Glycemic --> glycem\n",
            "control --> control\n",
            "through --> through\n",
            "insulin --> insulin\n",
            "therapy --> therapi\n",
            "and --> and\n",
            "oral --> oral\n",
            "hypoglycemics --> hypoglycem\n",
            "remains --> remain\n",
            "challenging --> challeng\n",
            ". --> .\n",
            "Abstract --> abstract\n",
            "2 --> 2\n",
            ": --> :\n",
            "Acute --> acut\n",
            "coronary --> coronari\n",
            "syndrome --> syndrom\n",
            "( --> (\n",
            "ACS --> ac\n",
            ") --> )\n",
            "presents --> present\n",
            "with --> with\n",
            "chest --> chest\n",
            "pain --> pain\n",
            ", --> ,\n",
            "dyspnea --> dyspnea\n",
            ", --> ,\n",
            "and --> and\n",
            "diaphoresis --> diaphoresi\n",
            ". --> .\n",
            "Troponin --> troponin\n",
            "levels --> level\n",
            "and --> and\n",
            "ECG --> ecg\n",
            "changes --> chang\n",
            "guide --> guid\n",
            "thrombolytic --> thrombolyt\n",
            "therapy --> therapi\n",
            "and --> and\n",
            "percutaneous --> percutan\n",
            "coronary --> coronari\n",
            "intervention --> intervent\n",
            "( --> (\n",
            "PCI --> pci\n",
            ") --> )\n",
            ". --> .\n",
            "Abstract --> abstract\n",
            "3 --> 3\n",
            ": --> :\n",
            "Chronic --> chronic\n",
            "kidney --> kidney\n",
            "disease --> diseas\n",
            "( --> (\n",
            "CKD --> ckd\n",
            ") --> )\n",
            "progression --> progress\n",
            "correlates --> correl\n",
            "with --> with\n",
            "proteinuria --> proteinuria\n",
            "levels --> level\n",
            "and --> and\n",
            "glomerular --> glomerular\n",
            "filtration --> filtrat\n",
            "rate --> rate\n",
            "( --> (\n",
            "GFR --> gfr\n",
            ") --> )\n",
            ". --> .\n",
            "Renin-angiotensin-aldosterone --> renin-angiotensin-aldosteron\n",
            "system --> system\n",
            "( --> (\n",
            "RAAS --> raa\n",
            ") --> )\n",
            "inhibitors --> inhibitor\n",
            "slow --> slow\n",
            "disease --> diseas\n",
            "advancement --> advanc\n",
            ". --> .\n",
            "Abstract --> abstract\n",
            "4 --> 4\n",
            ": --> :\n",
            "Alzheimer --> alzheim\n",
            "'s --> 's\n",
            "disease --> diseas\n",
            "( --> (\n",
            "AD --> ad\n",
            ") --> )\n",
            "pathology --> patholog\n",
            "involves --> involv\n",
            "amyloid-beta --> amyloid-beta\n",
            "plaques --> plaqu\n",
            "and --> and\n",
            "tau --> tau\n",
            "tangles --> tangl\n",
            ". --> .\n",
            "Cholinesterase --> cholinesteras\n",
            "inhibitors --> inhibitor\n",
            "provide --> provid\n",
            "symptomatic --> symptomat\n",
            "relief --> relief\n",
            "but --> but\n",
            "disease-modifying --> disease-modifi\n",
            "therapies --> therapi\n",
            "remain --> remain\n",
            "elusive --> elus\n",
            ". --> .\n",
            "Abstract --> abstract\n",
            "5 --> 5\n",
            ": --> :\n",
            "Sepsis --> sepsi\n",
            "management --> manag\n",
            "requires --> requir\n",
            "early --> earli\n",
            "recognition --> recognit\n",
            "through --> through\n",
            "qSOFA --> qsofa\n",
            "criteria --> criteria\n",
            "and --> and\n",
            "prompt --> prompt\n",
            "broad-spectrum --> broad-spectrum\n",
            "antibiotics --> antibiot\n",
            ". --> .\n",
            "Lactate --> lactat\n",
            "clearance --> clearanc\n",
            "monitoring --> monitor\n",
            "guides --> guid\n",
            "resuscitation --> resuscit\n",
            "efforts --> effort\n",
            ". --> .\n",
            "Abstract --> abstract\n",
            "6 --> 6\n",
            ": --> :\n",
            "Rheumatoid --> rheumatoid\n",
            "arthritis --> arthriti\n",
            "( --> (\n",
            "RA --> ra\n",
            ") --> )\n",
            "treatment --> treatment\n",
            "escalates --> escal\n",
            "from --> from\n",
            "methotrexate --> methotrex\n",
            "monotherapy --> monotherapi\n",
            "to --> to\n",
            "biologic --> biolog\n",
            "DMARDs --> dmard\n",
            "including --> includ\n",
            "TNF --> tnf\n",
            "inhibitors --> inhibitor\n",
            "when --> when\n",
            "disease --> diseas\n",
            "activity --> activ\n",
            "persists --> persist\n",
            ". --> .\n",
            "Abstract --> abstract\n",
            "7 --> 7\n",
            ": --> :\n",
            "Colorectal --> colorect\n",
            "cancer --> cancer\n",
            "screening --> screen\n",
            "via --> via\n",
            "fecal --> fecal\n",
            "immunochemical --> immunochem\n",
            "testing --> test\n",
            "( --> (\n",
            "FIT --> fit\n",
            ") --> )\n",
            "detects --> detect\n",
            "occult --> occult\n",
            "blood --> blood\n",
            "indicating --> indic\n",
            "colonoscopy --> colonoscopi\n",
            "for --> for\n",
            "polyp --> polyp\n",
            "resection --> resect\n",
            "and --> and\n",
            "early-stage --> early-stag\n",
            "intervention --> intervent\n",
            ". --> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lancaster Stemmer"
      ],
      "metadata": {
        "id": "ut0SwfeW8AJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import LancasterStemmer\n",
        "Lanc = LancasterStemmer()\n",
        "words = word_tokenize(medical_corpus)\n",
        "for word in words:\n",
        "  print(word,\"--->\",Lanc.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qq-_K01-8DTS",
        "outputId": "4f876992-0c4f-4a91-ccd7-442f3cd0fb90"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Abstract ---> abstract\n",
            "1 ---> 1\n",
            ": ---> :\n",
            "Patients ---> paty\n",
            "with ---> with\n",
            "diabetes ---> diabet\n",
            "mellitus ---> mellit\n",
            "type ---> typ\n",
            "2 ---> 2\n",
            "( ---> (\n",
            "DM2 ---> dm2\n",
            ") ---> )\n",
            "often ---> oft\n",
            "experience ---> expery\n",
            "cardiovascular ---> cardiovascul\n",
            "complications ---> comply\n",
            "including ---> includ\n",
            "myocardial ---> myocard\n",
            "infarction ---> infarct\n",
            "and ---> and\n",
            "stroke ---> stroke\n",
            ". ---> .\n",
            "Glycemic ---> glycem\n",
            "control ---> control\n",
            "through ---> through\n",
            "insulin ---> insulin\n",
            "therapy ---> therapy\n",
            "and ---> and\n",
            "oral ---> or\n",
            "hypoglycemics ---> hypoglycem\n",
            "remains ---> remain\n",
            "challenging ---> challeng\n",
            ". ---> .\n",
            "Abstract ---> abstract\n",
            "2 ---> 2\n",
            ": ---> :\n",
            "Acute ---> acut\n",
            "coronary ---> coron\n",
            "syndrome ---> syndrom\n",
            "( ---> (\n",
            "ACS ---> ac\n",
            ") ---> )\n",
            "presents ---> pres\n",
            "with ---> with\n",
            "chest ---> chest\n",
            "pain ---> pain\n",
            ", ---> ,\n",
            "dyspnea ---> dyspne\n",
            ", ---> ,\n",
            "and ---> and\n",
            "diaphoresis ---> diaphores\n",
            ". ---> .\n",
            "Troponin ---> troponin\n",
            "levels ---> level\n",
            "and ---> and\n",
            "ECG ---> ecg\n",
            "changes ---> chang\n",
            "guide ---> guid\n",
            "thrombolytic ---> thrombolytic\n",
            "therapy ---> therapy\n",
            "and ---> and\n",
            "percutaneous ---> percut\n",
            "coronary ---> coron\n",
            "intervention ---> interv\n",
            "( ---> (\n",
            "PCI ---> pci\n",
            ") ---> )\n",
            ". ---> .\n",
            "Abstract ---> abstract\n",
            "3 ---> 3\n",
            ": ---> :\n",
            "Chronic ---> chronic\n",
            "kidney ---> kidney\n",
            "disease ---> diseas\n",
            "( ---> (\n",
            "CKD ---> ckd\n",
            ") ---> )\n",
            "progression ---> progress\n",
            "correlates ---> correl\n",
            "with ---> with\n",
            "proteinuria ---> proteinur\n",
            "levels ---> level\n",
            "and ---> and\n",
            "glomerular ---> glomerul\n",
            "filtration ---> filt\n",
            "rate ---> rat\n",
            "( ---> (\n",
            "GFR ---> gfr\n",
            ") ---> )\n",
            ". ---> .\n",
            "Renin-angiotensin-aldosterone ---> renin-angiotensin-aldosterone\n",
            "system ---> system\n",
            "( ---> (\n",
            "RAAS ---> raa\n",
            ") ---> )\n",
            "inhibitors ---> inhibit\n",
            "slow ---> slow\n",
            "disease ---> diseas\n",
            "advancement ---> adv\n",
            ". ---> .\n",
            "Abstract ---> abstract\n",
            "4 ---> 4\n",
            ": ---> :\n",
            "Alzheimer ---> alzheim\n",
            "'s ---> 's\n",
            "disease ---> diseas\n",
            "( ---> (\n",
            "AD ---> ad\n",
            ") ---> )\n",
            "pathology ---> patholog\n",
            "involves ---> involv\n",
            "amyloid-beta ---> amyloid-beta\n",
            "plaques ---> plaqu\n",
            "and ---> and\n",
            "tau ---> tau\n",
            "tangles ---> tangl\n",
            ". ---> .\n",
            "Cholinesterase ---> cholinesteras\n",
            "inhibitors ---> inhibit\n",
            "provide ---> provid\n",
            "symptomatic ---> symptom\n",
            "relief ---> reliev\n",
            "but ---> but\n",
            "disease-modifying ---> disease-modifying\n",
            "therapies ---> therapy\n",
            "remain ---> remain\n",
            "elusive ---> elud\n",
            ". ---> .\n",
            "Abstract ---> abstract\n",
            "5 ---> 5\n",
            ": ---> :\n",
            "Sepsis ---> seps\n",
            "management ---> man\n",
            "requires ---> requir\n",
            "early ---> ear\n",
            "recognition ---> recognit\n",
            "through ---> through\n",
            "qSOFA ---> qsof\n",
            "criteria ---> criter\n",
            "and ---> and\n",
            "prompt ---> prompt\n",
            "broad-spectrum ---> broad-spectrum\n",
            "antibiotics ---> antibiot\n",
            ". ---> .\n",
            "Lactate ---> lact\n",
            "clearance ---> clear\n",
            "monitoring ---> monit\n",
            "guides ---> guid\n",
            "resuscitation ---> resuscit\n",
            "efforts ---> effort\n",
            ". ---> .\n",
            "Abstract ---> abstract\n",
            "6 ---> 6\n",
            ": ---> :\n",
            "Rheumatoid ---> rheumatoid\n",
            "arthritis ---> arthrit\n",
            "( ---> (\n",
            "RA ---> ra\n",
            ") ---> )\n",
            "treatment ---> tre\n",
            "escalates ---> esc\n",
            "from ---> from\n",
            "methotrexate ---> methotrex\n",
            "monotherapy ---> monotherapy\n",
            "to ---> to\n",
            "biologic ---> biolog\n",
            "DMARDs ---> dmard\n",
            "including ---> includ\n",
            "TNF ---> tnf\n",
            "inhibitors ---> inhibit\n",
            "when ---> when\n",
            "disease ---> diseas\n",
            "activity ---> act\n",
            "persists ---> persist\n",
            ". ---> .\n",
            "Abstract ---> abstract\n",
            "7 ---> 7\n",
            ": ---> :\n",
            "Colorectal ---> colorect\n",
            "cancer ---> cant\n",
            "screening ---> screening\n",
            "via ---> via\n",
            "fecal ---> fec\n",
            "immunochemical ---> immunochem\n",
            "testing ---> test\n",
            "( ---> (\n",
            "FIT ---> fit\n",
            ") ---> )\n",
            "detects ---> detect\n",
            "occult ---> occult\n",
            "blood ---> blood\n",
            "indicating ---> ind\n",
            "colonoscopy ---> colonoscop\n",
            "for ---> for\n",
            "polyp ---> polyp\n",
            "resection ---> resect\n",
            "and ---> and\n",
            "early-stage ---> early-stage\n",
            "intervention ---> interv\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regexp Stemmer"
      ],
      "metadata": {
        "id": "xD1-7IgE8WvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "reg = RegexpStemmer('ing$|s$|e$|able$', min=4)\n",
        "words = word_tokenize(medical_corpus)\n",
        "for word in words:\n",
        "  print(word,\"--->\",reg.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OxLq248P8ZpM",
        "outputId": "c42be997-70cc-4806-bb47-05c2f26bd15c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Abstract ---> Abstract\n",
            "1 ---> 1\n",
            ": ---> :\n",
            "Patients ---> Patient\n",
            "with ---> with\n",
            "diabetes ---> diabete\n",
            "mellitus ---> mellitu\n",
            "type ---> typ\n",
            "2 ---> 2\n",
            "( ---> (\n",
            "DM2 ---> DM2\n",
            ") ---> )\n",
            "often ---> often\n",
            "experience ---> experienc\n",
            "cardiovascular ---> cardiovascular\n",
            "complications ---> complication\n",
            "including ---> includ\n",
            "myocardial ---> myocardial\n",
            "infarction ---> infarction\n",
            "and ---> and\n",
            "stroke ---> strok\n",
            ". ---> .\n",
            "Glycemic ---> Glycemic\n",
            "control ---> control\n",
            "through ---> through\n",
            "insulin ---> insulin\n",
            "therapy ---> therapy\n",
            "and ---> and\n",
            "oral ---> oral\n",
            "hypoglycemics ---> hypoglycemic\n",
            "remains ---> remain\n",
            "challenging ---> challeng\n",
            ". ---> .\n",
            "Abstract ---> Abstract\n",
            "2 ---> 2\n",
            ": ---> :\n",
            "Acute ---> Acut\n",
            "coronary ---> coronary\n",
            "syndrome ---> syndrom\n",
            "( ---> (\n",
            "ACS ---> ACS\n",
            ") ---> )\n",
            "presents ---> present\n",
            "with ---> with\n",
            "chest ---> chest\n",
            "pain ---> pain\n",
            ", ---> ,\n",
            "dyspnea ---> dyspnea\n",
            ", ---> ,\n",
            "and ---> and\n",
            "diaphoresis ---> diaphoresi\n",
            ". ---> .\n",
            "Troponin ---> Troponin\n",
            "levels ---> level\n",
            "and ---> and\n",
            "ECG ---> ECG\n",
            "changes ---> change\n",
            "guide ---> guid\n",
            "thrombolytic ---> thrombolytic\n",
            "therapy ---> therapy\n",
            "and ---> and\n",
            "percutaneous ---> percutaneou\n",
            "coronary ---> coronary\n",
            "intervention ---> intervention\n",
            "( ---> (\n",
            "PCI ---> PCI\n",
            ") ---> )\n",
            ". ---> .\n",
            "Abstract ---> Abstract\n",
            "3 ---> 3\n",
            ": ---> :\n",
            "Chronic ---> Chronic\n",
            "kidney ---> kidney\n",
            "disease ---> diseas\n",
            "( ---> (\n",
            "CKD ---> CKD\n",
            ") ---> )\n",
            "progression ---> progression\n",
            "correlates ---> correlate\n",
            "with ---> with\n",
            "proteinuria ---> proteinuria\n",
            "levels ---> level\n",
            "and ---> and\n",
            "glomerular ---> glomerular\n",
            "filtration ---> filtration\n",
            "rate ---> rat\n",
            "( ---> (\n",
            "GFR ---> GFR\n",
            ") ---> )\n",
            ". ---> .\n",
            "Renin-angiotensin-aldosterone ---> Renin-angiotensin-aldosteron\n",
            "system ---> system\n",
            "( ---> (\n",
            "RAAS ---> RAAS\n",
            ") ---> )\n",
            "inhibitors ---> inhibitor\n",
            "slow ---> slow\n",
            "disease ---> diseas\n",
            "advancement ---> advancement\n",
            ". ---> .\n",
            "Abstract ---> Abstract\n",
            "4 ---> 4\n",
            ": ---> :\n",
            "Alzheimer ---> Alzheimer\n",
            "'s ---> 's\n",
            "disease ---> diseas\n",
            "( ---> (\n",
            "AD ---> AD\n",
            ") ---> )\n",
            "pathology ---> pathology\n",
            "involves ---> involve\n",
            "amyloid-beta ---> amyloid-beta\n",
            "plaques ---> plaque\n",
            "and ---> and\n",
            "tau ---> tau\n",
            "tangles ---> tangle\n",
            ". ---> .\n",
            "Cholinesterase ---> Cholinesteras\n",
            "inhibitors ---> inhibitor\n",
            "provide ---> provid\n",
            "symptomatic ---> symptomatic\n",
            "relief ---> relief\n",
            "but ---> but\n",
            "disease-modifying ---> disease-modify\n",
            "therapies ---> therapie\n",
            "remain ---> remain\n",
            "elusive ---> elusiv\n",
            ". ---> .\n",
            "Abstract ---> Abstract\n",
            "5 ---> 5\n",
            ": ---> :\n",
            "Sepsis ---> Sepsi\n",
            "management ---> management\n",
            "requires ---> require\n",
            "early ---> early\n",
            "recognition ---> recognition\n",
            "through ---> through\n",
            "qSOFA ---> qSOFA\n",
            "criteria ---> criteria\n",
            "and ---> and\n",
            "prompt ---> prompt\n",
            "broad-spectrum ---> broad-spectrum\n",
            "antibiotics ---> antibiotic\n",
            ". ---> .\n",
            "Lactate ---> Lactat\n",
            "clearance ---> clearanc\n",
            "monitoring ---> monitor\n",
            "guides ---> guide\n",
            "resuscitation ---> resuscitation\n",
            "efforts ---> effort\n",
            ". ---> .\n",
            "Abstract ---> Abstract\n",
            "6 ---> 6\n",
            ": ---> :\n",
            "Rheumatoid ---> Rheumatoid\n",
            "arthritis ---> arthriti\n",
            "( ---> (\n",
            "RA ---> RA\n",
            ") ---> )\n",
            "treatment ---> treatment\n",
            "escalates ---> escalate\n",
            "from ---> from\n",
            "methotrexate ---> methotrexat\n",
            "monotherapy ---> monotherapy\n",
            "to ---> to\n",
            "biologic ---> biologic\n",
            "DMARDs ---> DMARD\n",
            "including ---> includ\n",
            "TNF ---> TNF\n",
            "inhibitors ---> inhibitor\n",
            "when ---> when\n",
            "disease ---> diseas\n",
            "activity ---> activity\n",
            "persists ---> persist\n",
            ". ---> .\n",
            "Abstract ---> Abstract\n",
            "7 ---> 7\n",
            ": ---> :\n",
            "Colorectal ---> Colorectal\n",
            "cancer ---> cancer\n",
            "screening ---> screen\n",
            "via ---> via\n",
            "fecal ---> fecal\n",
            "immunochemical ---> immunochemical\n",
            "testing ---> test\n",
            "( ---> (\n",
            "FIT ---> FIT\n",
            ") ---> )\n",
            "detects ---> detect\n",
            "occult ---> occult\n",
            "blood ---> blood\n",
            "indicating ---> indicat\n",
            "colonoscopy ---> colonoscopy\n",
            "for ---> for\n",
            "polyp ---> polyp\n",
            "resection ---> resection\n",
            "and ---> and\n",
            "early-stage ---> early-stag\n",
            "intervention ---> intervention\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Here we need to do **lemmatization** for the tokenized words"
      ],
      "metadata": {
        "id": "tUYuHFdx51n0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = word_tokenize(medical_corpus)\n",
        "for word in words:\n",
        "  print(word,\"--->\",lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "id": "rD6IsmOz9GpY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "104c4e68-d9fc-4b87-f4ea-4d0ad1c4fc29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Abstract ---> Abstract\n",
            "1 ---> 1\n",
            ": ---> :\n",
            "Patients ---> Patients\n",
            "with ---> with\n",
            "diabetes ---> diabetes\n",
            "mellitus ---> mellitus\n",
            "type ---> type\n",
            "2 ---> 2\n",
            "( ---> (\n",
            "DM2 ---> DM2\n",
            ") ---> )\n",
            "often ---> often\n",
            "experience ---> experience\n",
            "cardiovascular ---> cardiovascular\n",
            "complications ---> complication\n",
            "including ---> including\n",
            "myocardial ---> myocardial\n",
            "infarction ---> infarction\n",
            "and ---> and\n",
            "stroke ---> stroke\n",
            ". ---> .\n",
            "Glycemic ---> Glycemic\n",
            "control ---> control\n",
            "through ---> through\n",
            "insulin ---> insulin\n",
            "therapy ---> therapy\n",
            "and ---> and\n",
            "oral ---> oral\n",
            "hypoglycemics ---> hypoglycemics\n",
            "remains ---> remains\n",
            "challenging ---> challenging\n",
            ". ---> .\n",
            "Abstract ---> Abstract\n",
            "2 ---> 2\n",
            ": ---> :\n",
            "Acute ---> Acute\n",
            "coronary ---> coronary\n",
            "syndrome ---> syndrome\n",
            "( ---> (\n",
            "ACS ---> ACS\n",
            ") ---> )\n",
            "presents ---> present\n",
            "with ---> with\n",
            "chest ---> chest\n",
            "pain ---> pain\n",
            ", ---> ,\n",
            "dyspnea ---> dyspnea\n",
            ", ---> ,\n",
            "and ---> and\n",
            "diaphoresis ---> diaphoresis\n",
            ". ---> .\n",
            "Troponin ---> Troponin\n",
            "levels ---> level\n",
            "and ---> and\n",
            "ECG ---> ECG\n",
            "changes ---> change\n",
            "guide ---> guide\n",
            "thrombolytic ---> thrombolytic\n",
            "therapy ---> therapy\n",
            "and ---> and\n",
            "percutaneous ---> percutaneous\n",
            "coronary ---> coronary\n",
            "intervention ---> intervention\n",
            "( ---> (\n",
            "PCI ---> PCI\n",
            ") ---> )\n",
            ". ---> .\n",
            "Abstract ---> Abstract\n",
            "3 ---> 3\n",
            ": ---> :\n",
            "Chronic ---> Chronic\n",
            "kidney ---> kidney\n",
            "disease ---> disease\n",
            "( ---> (\n",
            "CKD ---> CKD\n",
            ") ---> )\n",
            "progression ---> progression\n",
            "correlates ---> correlate\n",
            "with ---> with\n",
            "proteinuria ---> proteinuria\n",
            "levels ---> level\n",
            "and ---> and\n",
            "glomerular ---> glomerular\n",
            "filtration ---> filtration\n",
            "rate ---> rate\n",
            "( ---> (\n",
            "GFR ---> GFR\n",
            ") ---> )\n",
            ". ---> .\n",
            "Renin-angiotensin-aldosterone ---> Renin-angiotensin-aldosterone\n",
            "system ---> system\n",
            "( ---> (\n",
            "RAAS ---> RAAS\n",
            ") ---> )\n",
            "inhibitors ---> inhibitor\n",
            "slow ---> slow\n",
            "disease ---> disease\n",
            "advancement ---> advancement\n",
            ". ---> .\n",
            "Abstract ---> Abstract\n",
            "4 ---> 4\n",
            ": ---> :\n",
            "Alzheimer ---> Alzheimer\n",
            "'s ---> 's\n",
            "disease ---> disease\n",
            "( ---> (\n",
            "AD ---> AD\n",
            ") ---> )\n",
            "pathology ---> pathology\n",
            "involves ---> involves\n",
            "amyloid-beta ---> amyloid-beta\n",
            "plaques ---> plaque\n",
            "and ---> and\n",
            "tau ---> tau\n",
            "tangles ---> tangle\n",
            ". ---> .\n",
            "Cholinesterase ---> Cholinesterase\n",
            "inhibitors ---> inhibitor\n",
            "provide ---> provide\n",
            "symptomatic ---> symptomatic\n",
            "relief ---> relief\n",
            "but ---> but\n",
            "disease-modifying ---> disease-modifying\n",
            "therapies ---> therapy\n",
            "remain ---> remain\n",
            "elusive ---> elusive\n",
            ". ---> .\n",
            "Abstract ---> Abstract\n",
            "5 ---> 5\n",
            ": ---> :\n",
            "Sepsis ---> Sepsis\n",
            "management ---> management\n",
            "requires ---> requires\n",
            "early ---> early\n",
            "recognition ---> recognition\n",
            "through ---> through\n",
            "qSOFA ---> qSOFA\n",
            "criteria ---> criterion\n",
            "and ---> and\n",
            "prompt ---> prompt\n",
            "broad-spectrum ---> broad-spectrum\n",
            "antibiotics ---> antibiotic\n",
            ". ---> .\n",
            "Lactate ---> Lactate\n",
            "clearance ---> clearance\n",
            "monitoring ---> monitoring\n",
            "guides ---> guide\n",
            "resuscitation ---> resuscitation\n",
            "efforts ---> effort\n",
            ". ---> .\n",
            "Abstract ---> Abstract\n",
            "6 ---> 6\n",
            ": ---> :\n",
            "Rheumatoid ---> Rheumatoid\n",
            "arthritis ---> arthritis\n",
            "( ---> (\n",
            "RA ---> RA\n",
            ") ---> )\n",
            "treatment ---> treatment\n",
            "escalates ---> escalates\n",
            "from ---> from\n",
            "methotrexate ---> methotrexate\n",
            "monotherapy ---> monotherapy\n",
            "to ---> to\n",
            "biologic ---> biologic\n",
            "DMARDs ---> DMARDs\n",
            "including ---> including\n",
            "TNF ---> TNF\n",
            "inhibitors ---> inhibitor\n",
            "when ---> when\n",
            "disease ---> disease\n",
            "activity ---> activity\n",
            "persists ---> persists\n",
            ". ---> .\n",
            "Abstract ---> Abstract\n",
            "7 ---> 7\n",
            ": ---> :\n",
            "Colorectal ---> Colorectal\n",
            "cancer ---> cancer\n",
            "screening ---> screening\n",
            "via ---> via\n",
            "fecal ---> fecal\n",
            "immunochemical ---> immunochemical\n",
            "testing ---> testing\n",
            "( ---> (\n",
            "FIT ---> FIT\n",
            ") ---> )\n",
            "detects ---> detects\n",
            "occult ---> occult\n",
            "blood ---> blood\n",
            "indicating ---> indicating\n",
            "colonoscopy ---> colonoscopy\n",
            "for ---> for\n",
            "polyp ---> polyp\n",
            "resection ---> resection\n",
            "and ---> and\n",
            "early-stage ---> early-stage\n",
            "intervention ---> intervention\n",
            ". ---> .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# comparision"
      ],
      "metadata": {
        "id": "p5489vZA8sLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer, RegexpStemmer, WordNetLemmatizer\n",
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "snowball = SnowballStemmer(language='english')\n",
        "regexp = RegexpStemmer('ing|e', min=4)\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "word_list = [\"friend\", \"friendship\", \"friends\", \"friendships\"]\n",
        "print(\"{0:20}{1:20}{2:20}{3:30}{4:40}{5:50}\".format(\"Word\",\"Porter Stemmer\",\"Snowball Stemmer\",\"Lancaster Stemmer\",'Regexp Stemmer','WordNetLemmatizer'))\n",
        "for word in word_list:\n",
        "    print(\"{0:20}{1:20}{2:20}{3:30}{4:40}{5:50}\".format(word,porter.stem(word),snowball.stem(word),lancaster.stem(word),regexp.stem(word),lemmatizer.lemmatize(word)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IOlEwkpC8uKT",
        "outputId": "131d3b35-6ee7-4bc5-c6a2-84da58a583b7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                Porter Stemmer      Snowball Stemmer    Lancaster Stemmer             Regexp Stemmer                          WordNetLemmatizer                                 \n",
            "friend              friend              friend              friend                        frind                                   friend                                            \n",
            "friendship          friendship          friendship          friend                        frindship                               friendship                                        \n",
            "friends             friend              friend              friend                        frinds                                  friend                                            \n",
            "friendships         friendship          friendship          friend                        frindships                              friendship                                        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Why lemmatization is important in healthcare and nlp\n",
        "\n",
        "# Lemmatization is important to reduce the complexity of the memory and lemmatization brings the words to its root or stem form with the dictionary meaning words.For critical and basic words for understanding in healthcare we use lemmatization.Where health is a sensitive topic"
      ],
      "metadata": {
        "id": "qU5Rct299E-U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GITHUB ASSIGNMENT"
      ],
      "metadata": {
        "id": "VdF60k4h9JLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message = \"\"\"Trees represent vital perennial plants distinguished by single trunks, branches, and crowns that sustain ecosystems.\n",
        "Classified mainly as deciduous (e.g., maple, losing leaves seasonally) or evergreen (e.g., fir, retaining foliage), they adapt to diverse climates.\"\"\""
      ],
      "metadata": {
        "id": "QpLcJjVt9U2X"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "Y_JUgVhb91rR",
        "outputId": "9ea7edb8-ede7-43ff-c6f4-cde221ca12c8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Trees represent vital perennial plants distinguished by single trunks, branches, and crowns that sustain ecosystems.\\u200b\\nClassified mainly as deciduous (e.g., maple, losing leaves seasonally) or evergreen (e.g., fir, retaining foliage), they adapt to diverse climates.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "mgVAfKRV95dV",
        "outputId": "f528ff03-551b-4b35-ba2b-f8ee245435e9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Trees',\n",
              " 'represent',\n",
              " 'vital',\n",
              " 'perennial',\n",
              " 'plants',\n",
              " 'distinguished',\n",
              " 'by',\n",
              " 'single',\n",
              " 'trunks',\n",
              " ',',\n",
              " 'branches',\n",
              " ',',\n",
              " 'and',\n",
              " 'crowns',\n",
              " 'that',\n",
              " 'sustain',\n",
              " 'ecosystems.\\u200b',\n",
              " 'Classified',\n",
              " 'mainly',\n",
              " 'as',\n",
              " 'deciduous',\n",
              " '(',\n",
              " 'e.g.',\n",
              " ',',\n",
              " 'maple',\n",
              " ',',\n",
              " 'losing',\n",
              " 'leaves',\n",
              " 'seasonally',\n",
              " ')',\n",
              " 'or',\n",
              " 'evergreen',\n",
              " '(',\n",
              " 'e.g.',\n",
              " ',',\n",
              " 'fir',\n",
              " ',',\n",
              " 'retaining',\n",
              " 'foliage',\n",
              " ')',\n",
              " ',',\n",
              " 'they',\n",
              " 'adapt',\n",
              " 'to',\n",
              " 'diverse',\n",
              " 'climates',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sent_tokenize(message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KlOuAnzT-XiC",
        "outputId": "95e84dd6-6b5a-45d5-ba3b-4fd6a57e147a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Trees represent vital perennial plants distinguished by single trunks, branches, and crowns that sustain ecosystems.\\u200b\\nClassified mainly as deciduous (e.g., maple, losing leaves seasonally) or evergreen (e.g., fir, retaining foliage), they adapt to diverse climates.']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# filtering stop words"
      ],
      "metadata": {
        "id": "cXbDz1Ys-odC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zV__jyqa-rTV",
        "outputId": "da5df02d-ce93-4b8e-ede2-8a2f5a85cf01"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_quote = word_tokenize(message)\n",
        "words_in_quote"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BiblCq_I-u6S",
        "outputId": "bb928c21-19a2-4f1a-a078-b5734e5d4fdd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Trees',\n",
              " 'represent',\n",
              " 'vital',\n",
              " 'perennial',\n",
              " 'plants',\n",
              " 'distinguished',\n",
              " 'by',\n",
              " 'single',\n",
              " 'trunks',\n",
              " ',',\n",
              " 'branches',\n",
              " ',',\n",
              " 'and',\n",
              " 'crowns',\n",
              " 'that',\n",
              " 'sustain',\n",
              " 'ecosystems.\\u200b',\n",
              " 'Classified',\n",
              " 'mainly',\n",
              " 'as',\n",
              " 'deciduous',\n",
              " '(',\n",
              " 'e.g.',\n",
              " ',',\n",
              " 'maple',\n",
              " ',',\n",
              " 'losing',\n",
              " 'leaves',\n",
              " 'seasonally',\n",
              " ')',\n",
              " 'or',\n",
              " 'evergreen',\n",
              " '(',\n",
              " 'e.g.',\n",
              " ',',\n",
              " 'fir',\n",
              " ',',\n",
              " 'retaining',\n",
              " 'foliage',\n",
              " ')',\n",
              " ',',\n",
              " 'they',\n",
              " 'adapt',\n",
              " 'to',\n",
              " 'diverse',\n",
              " 'climates',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "filtered_list = []\n",
        "for word in words_in_quote:\n",
        "  if word.casefold() not in stop_words:\n",
        "    filtered_list.append(word)\n",
        "filtered_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JblNow2Q-90e",
        "outputId": "55dbb4f4-ccda-4cfa-b203-a9ff14227c55"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Trees',\n",
              " 'represent',\n",
              " 'vital',\n",
              " 'perennial',\n",
              " 'plants',\n",
              " 'distinguished',\n",
              " 'single',\n",
              " 'trunks',\n",
              " ',',\n",
              " 'branches',\n",
              " ',',\n",
              " 'crowns',\n",
              " 'sustain',\n",
              " 'ecosystems.\\u200b',\n",
              " 'Classified',\n",
              " 'mainly',\n",
              " 'deciduous',\n",
              " '(',\n",
              " 'e.g.',\n",
              " ',',\n",
              " 'maple',\n",
              " ',',\n",
              " 'losing',\n",
              " 'leaves',\n",
              " 'seasonally',\n",
              " ')',\n",
              " 'evergreen',\n",
              " '(',\n",
              " 'e.g.',\n",
              " ',',\n",
              " 'fir',\n",
              " ',',\n",
              " 'retaining',\n",
              " 'foliage',\n",
              " ')',\n",
              " ',',\n",
              " 'adapt',\n",
              " 'diverse',\n",
              " 'climates',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# stemming"
      ],
      "metadata": {
        "id": "IgyF4oet_Gji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "ps = PorterStemmer()\n",
        "words = word_tokenize(message)\n",
        "stemmed_words = [ps.stem(word) for word in words]\n",
        "stemmed_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "szVNEavr_It2",
        "outputId": "df9043a1-21c3-4cdd-db9e-613bdd03b79f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tree',\n",
              " 'repres',\n",
              " 'vital',\n",
              " 'perenni',\n",
              " 'plant',\n",
              " 'distinguish',\n",
              " 'by',\n",
              " 'singl',\n",
              " 'trunk',\n",
              " ',',\n",
              " 'branch',\n",
              " ',',\n",
              " 'and',\n",
              " 'crown',\n",
              " 'that',\n",
              " 'sustain',\n",
              " 'ecosystems.\\u200b',\n",
              " 'classifi',\n",
              " 'mainli',\n",
              " 'as',\n",
              " 'decidu',\n",
              " '(',\n",
              " 'e.g.',\n",
              " ',',\n",
              " 'mapl',\n",
              " ',',\n",
              " 'lose',\n",
              " 'leav',\n",
              " 'season',\n",
              " ')',\n",
              " 'or',\n",
              " 'evergreen',\n",
              " '(',\n",
              " 'e.g.',\n",
              " ',',\n",
              " 'fir',\n",
              " ',',\n",
              " 'retain',\n",
              " 'foliag',\n",
              " ')',\n",
              " ',',\n",
              " 'they',\n",
              " 'adapt',\n",
              " 'to',\n",
              " 'divers',\n",
              " 'climat',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk.stem import SnowballStemmer\n",
        "snowball = SnowballStemmer(language='english')\n",
        "words = word_tokenize(message)\n",
        "for word in words:\n",
        "    print(word,\"--->\",snowball.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zOlW73Q3_kuK",
        "outputId": "67ec4674-7f6a-45d0-9ae3-b8b5bd2afdd4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trees ---> tree\n",
            "represent ---> repres\n",
            "vital ---> vital\n",
            "perennial ---> perenni\n",
            "plants ---> plant\n",
            "distinguished ---> distinguish\n",
            "by ---> by\n",
            "single ---> singl\n",
            "trunks ---> trunk\n",
            ", ---> ,\n",
            "branches ---> branch\n",
            ", ---> ,\n",
            "and ---> and\n",
            "crowns ---> crown\n",
            "that ---> that\n",
            "sustain ---> sustain\n",
            "ecosystems. ---> ecosystems.\n",
            "Classified ---> classifi\n",
            "mainly ---> main\n",
            "as ---> as\n",
            "deciduous ---> decidu\n",
            "( ---> (\n",
            "e.g. ---> e.g.\n",
            ", ---> ,\n",
            "maple ---> mapl\n",
            ", ---> ,\n",
            "losing ---> lose\n",
            "leaves ---> leav\n",
            "seasonally ---> season\n",
            ") ---> )\n",
            "or ---> or\n",
            "evergreen ---> evergreen\n",
            "( ---> (\n",
            "e.g. ---> e.g.\n",
            ", ---> ,\n",
            "fir ---> fir\n",
            ", ---> ,\n",
            "retaining ---> retain\n",
            "foliage ---> foliag\n",
            ") ---> )\n",
            ", ---> ,\n",
            "they ---> they\n",
            "adapt ---> adapt\n",
            "to ---> to\n",
            "diverse ---> divers\n",
            "climates ---> climat\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import LancasterStemmer\n",
        "Lanc = LancasterStemmer()\n",
        "words = word_tokenize(message)\n",
        "for word in words:\n",
        "    print(word,\"--->\",Lanc.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vW0x5EZB_qUc",
        "outputId": "041b92da-6b29-4cf0-8c15-55348700f216"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trees ---> tre\n",
            "represent ---> repres\n",
            "vital ---> vit\n",
            "perennial ---> peren\n",
            "plants ---> plant\n",
            "distinguished ---> distinct\n",
            "by ---> by\n",
            "single ---> singl\n",
            "trunks ---> trunk\n",
            ", ---> ,\n",
            "branches ---> branch\n",
            ", ---> ,\n",
            "and ---> and\n",
            "crowns ---> crown\n",
            "that ---> that\n",
            "sustain ---> sustain\n",
            "ecosystems. ---> ecosystems.\n",
            "Classified ---> class\n",
            "mainly ---> main\n",
            "as ---> as\n",
            "deciduous ---> decidu\n",
            "( ---> (\n",
            "e.g. ---> e.g.\n",
            ", ---> ,\n",
            "maple ---> mapl\n",
            ", ---> ,\n",
            "losing ---> los\n",
            "leaves ---> leav\n",
            "seasonally ---> season\n",
            ") ---> )\n",
            "or ---> or\n",
            "evergreen ---> evergreen\n",
            "( ---> (\n",
            "e.g. ---> e.g.\n",
            ", ---> ,\n",
            "fir ---> fir\n",
            ", ---> ,\n",
            "retaining ---> retain\n",
            "foliage ---> foly\n",
            ") ---> )\n",
            ", ---> ,\n",
            "they ---> they\n",
            "adapt ---> adapt\n",
            "to ---> to\n",
            "diverse ---> divers\n",
            "climates ---> clim\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "regexp = RegexpStemmer('ing|e', min=4)\n",
        "words = word_tokenize(message)\n",
        "for word in words:\n",
        "    print(word,\"--->\",regexp.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "q57PN-Yz_u-j",
        "outputId": "47e218eb-88c3-4f16-c9de-b9fb12345d81"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trees ---> Trs\n",
            "represent ---> rprsnt\n",
            "vital ---> vital\n",
            "perennial ---> prnnial\n",
            "plants ---> plants\n",
            "distinguished ---> distuishd\n",
            "by ---> by\n",
            "single ---> sl\n",
            "trunks ---> trunks\n",
            ", ---> ,\n",
            "branches ---> branchs\n",
            ", ---> ,\n",
            "and ---> and\n",
            "crowns ---> crowns\n",
            "that ---> that\n",
            "sustain ---> sustain\n",
            "ecosystems. ---> cosystms.\n",
            "Classified ---> Classifid\n",
            "mainly ---> mainly\n",
            "as ---> as\n",
            "deciduous ---> dciduous\n",
            "( ---> (\n",
            "e.g. ---> .g.\n",
            ", ---> ,\n",
            "maple ---> mapl\n",
            ", ---> ,\n",
            "losing ---> los\n",
            "leaves ---> lavs\n",
            "seasonally ---> sasonally\n",
            ") ---> )\n",
            "or ---> or\n",
            "evergreen ---> vrgrn\n",
            "( ---> (\n",
            "e.g. ---> .g.\n",
            ", ---> ,\n",
            "fir ---> fir\n",
            ", ---> ,\n",
            "retaining ---> rtain\n",
            "foliage ---> foliag\n",
            ") ---> )\n",
            ", ---> ,\n",
            "they ---> thy\n",
            "adapt ---> adapt\n",
            "to ---> to\n",
            "diverse ---> divrs\n",
            "climates ---> climats\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization"
      ],
      "metadata": {
        "id": "vAP1zpGE_1vs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = word_tokenize(message)\n",
        "for word in words:\n",
        "    print(word,\"--->\",lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8Io9Vd_b_4GZ",
        "outputId": "84398eb1-5ed7-4f62-f24e-c83b0d06ad97"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trees ---> Trees\n",
            "represent ---> represent\n",
            "vital ---> vital\n",
            "perennial ---> perennial\n",
            "plants ---> plant\n",
            "distinguished ---> distinguished\n",
            "by ---> by\n",
            "single ---> single\n",
            "trunks ---> trunk\n",
            ", ---> ,\n",
            "branches ---> branch\n",
            ", ---> ,\n",
            "and ---> and\n",
            "crowns ---> crown\n",
            "that ---> that\n",
            "sustain ---> sustain\n",
            "ecosystems. ---> ecosystems.\n",
            "Classified ---> Classified\n",
            "mainly ---> mainly\n",
            "as ---> a\n",
            "deciduous ---> deciduous\n",
            "( ---> (\n",
            "e.g. ---> e.g.\n",
            ", ---> ,\n",
            "maple ---> maple\n",
            ", ---> ,\n",
            "losing ---> losing\n",
            "leaves ---> leaf\n",
            "seasonally ---> seasonally\n",
            ") ---> )\n",
            "or ---> or\n",
            "evergreen ---> evergreen\n",
            "( ---> (\n",
            "e.g. ---> e.g.\n",
            ", ---> ,\n",
            "fir ---> fir\n",
            ", ---> ,\n",
            "retaining ---> retaining\n",
            "foliage ---> foliage\n",
            ") ---> )\n",
            ", ---> ,\n",
            "they ---> they\n",
            "adapt ---> adapt\n",
            "to ---> to\n",
            "diverse ---> diverse\n",
            "climates ---> climate\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# comparision"
      ],
      "metadata": {
        "id": "N6Uj9T55_-zf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer, RegexpStemmer, WordNetLemmatizer\n",
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "snowball = SnowballStemmer(language='english')\n",
        "regexp = RegexpStemmer('ing|e', min=4)\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "word_list = [\"friend\", \"friendship\", \"friends\", \"friendships\"]\n",
        "print(\"{0:20}{1:20}{2:20}{3:30}{4:40}{5:50}\".format(\"Word\",\"Porter Stemmer\",\"Snowball Stemmer\",\"Lancaster Stemmer\",'Regexp Stemmer','WordNetLemmatizer'))\n",
        "for word in word_list:\n",
        "    print(\"{0:20}{1:20}{2:20}{3:30}{4:40}{5:50}\".format(word,porter.stem(word),snowball.stem(word),lancaster.stem(word),regexp.stem(word),lemmatizer.lemmatize(word)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-23caZhpAAgN",
        "outputId": "d8e13f8b-1aa6-4b89-ac7b-9e01fef20dd1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                Porter Stemmer      Snowball Stemmer    Lancaster Stemmer             Regexp Stemmer                          WordNetLemmatizer                                 \n",
            "friend              friend              friend              friend                        frind                                   friend                                            \n",
            "friendship          friendship          friendship          friend                        frindship                               friendship                                        \n",
            "friends             friend              friend              friend                        frinds                                  friend                                            \n",
            "friendships         friendship          friendship          friend                        frindships                              friendship                                        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tagging parts of speech"
      ],
      "metadata": {
        "id": "EK0LBhZKAVjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng') # Added this line\n",
        "from nltk.tokenize import word_tokenize\n",
        "words = word_tokenize(message)\n",
        "nltk.pos_tag(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TDbza4osAact",
        "outputId": "e1582244-737f-454d-f13f-bad6bebc6fcc"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Trees', 'NNS'),\n",
              " ('represent', 'VBP'),\n",
              " ('vital', 'JJ'),\n",
              " ('perennial', 'JJ'),\n",
              " ('plants', 'NNS'),\n",
              " ('distinguished', 'VBN'),\n",
              " ('by', 'IN'),\n",
              " ('single', 'JJ'),\n",
              " ('trunks', 'NNS'),\n",
              " (',', ','),\n",
              " ('branches', 'NNS'),\n",
              " (',', ','),\n",
              " ('and', 'CC'),\n",
              " ('crowns', 'NNS'),\n",
              " ('that', 'WDT'),\n",
              " ('sustain', 'VBP'),\n",
              " ('ecosystems.\\u200b', 'JJ'),\n",
              " ('Classified', 'NNP'),\n",
              " ('mainly', 'RB'),\n",
              " ('as', 'RB'),\n",
              " ('deciduous', 'JJ'),\n",
              " ('(', '('),\n",
              " ('e.g.', 'JJ'),\n",
              " (',', ','),\n",
              " ('maple', 'JJ'),\n",
              " (',', ','),\n",
              " ('losing', 'VBG'),\n",
              " ('leaves', 'NNS'),\n",
              " ('seasonally', 'RB'),\n",
              " (')', ')'),\n",
              " ('or', 'CC'),\n",
              " ('evergreen', 'JJ'),\n",
              " ('(', '('),\n",
              " ('e.g.', 'JJ'),\n",
              " (',', ','),\n",
              " ('fir', 'JJ'),\n",
              " (',', ','),\n",
              " ('retaining', 'VBG'),\n",
              " ('foliage', 'NN'),\n",
              " (')', ')'),\n",
              " (',', ','),\n",
              " ('they', 'PRP'),\n",
              " ('adapt', 'VBP'),\n",
              " ('to', 'TO'),\n",
              " ('diverse', 'VB'),\n",
              " ('climates', 'NNS'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# chunking"
      ],
      "metadata": {
        "id": "lHtUKPjXAn_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "lotr_quote = \"It's a dangerous business, Frodo, going out your door.\"\n",
        "words_in_lotr_quote = word_tokenize(lotr_quote)\n",
        "lotr_pos_tags = nltk.pos_tag(words_in_lotr_quote)\n",
        "grammar = \"NP: {<DT>?<JJ>*<NNP>?<NN>+}\"\n",
        "chunk_parser = nltk.RegexpParser(grammar)\n",
        "tree = chunk_parser.parse(lotr_pos_tags)\n",
        "print(tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_ZNFnB4YApyY",
        "outputId": "8ba1d8c6-4d76-4de9-cfda-787616d73875"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  It/PRP\n",
            "  's/VBZ\n",
            "  (NP a/DT dangerous/JJ business/NN)\n",
            "  ,/,\n",
            "  Frodo/NNP\n",
            "  ,/,\n",
            "  going/VBG\n",
            "  out/RP\n",
            "  your/PRP$\n",
            "  (NP door/NN)\n",
            "  ./.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# chinking"
      ],
      "metadata": {
        "id": "-uyLsoUzA3T-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "lotr_quote = \"It's a dangerous business, Frodo, going out your door.\"\n",
        "words_in_lotr_quote = word_tokenize(lotr_quote)\n",
        "lotr_pos_tags = nltk.pos_tag(words_in_lotr_quote)\n",
        "grammar = \"\"\"\n",
        "          CHUNK: {<.*>+} # Chunk everything\n",
        "                 }<DT>{   # Chink (remove) Determiners (DT)\n",
        "          \"\"\"\n",
        "chunk_parser = nltk.RegexpParser(grammar)\n",
        "tree = chunk_parser.parse(lotr_pos_tags)\n",
        "print(tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "icyaS73bA4rj",
        "outputId": "1bbf3590-1456-4957-afc2-af6d73010a01"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (CHUNK It/PRP 's/VBZ)\n",
            "  a/DT\n",
            "  (CHUNK\n",
            "    dangerous/JJ\n",
            "    business/NN\n",
            "    ,/,\n",
            "    Frodo/NNP\n",
            "    ,/,\n",
            "    going/VBG\n",
            "    out/RP\n",
            "    your/PRP$\n",
            "    door/NN\n",
            "    ./.))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NER"
      ],
      "metadata": {
        "id": "a4s2n8pMBEW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_ne(quote):\n",
        "  words = word_tokenize(quote)\n",
        "  tags = nltk.pos_tag(words)\n",
        "  tree = nltk.ne_chunk(tags, binary=True)\n",
        "  return set(\" \".join(i[0] for i in t)\n",
        "            for t in tree\n",
        "            if hasattr(t, \"label\") and t.label() == \"NE\"\n",
        "            )\n",
        "\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('maxent_ne_chunker_tab') # Added this line to download the missing resource\n",
        "extract_ne(\"I am siddhartha, from India, i am studing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RLXLeUXCBBfH",
        "outputId": "987842c0-283f-4b76-90c8-622a349f1bd3"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'India'}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# class assignment"
      ],
      "metadata": {
        "id": "hTsFTLv7Beda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task = \"\"\"\n",
        "NLP models are transforming the world rapidly!\"\"\""
      ],
      "metadata": {
        "id": "gTsfo_5UBiVV"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "HvRrvkQnCOvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize(task)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "34NP8kdXCFl3",
        "outputId": "4742c55c-b328-48b6-a9b4-56b86ed6f29c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NLP', 'models', 'are', 'transforming', 'the', 'world', 'rapidly', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokenize(task)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JY5hdb9XCJ5H",
        "outputId": "3ce33407-1429-43cd-e0ed-9e8e6d28a314"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\nNLP models are transforming the world rapidly!']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# filtering stop_word"
      ],
      "metadata": {
        "id": "z2Nfz6TkCZLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_quotes = word_tokenize(task)\n",
        "words_in_quotes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qCJkDaIlCdLO",
        "outputId": "54e25d60-0d00-4870-fad1-aeb584e87531"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NLP', 'models', 'are', 'transforming', 'the', 'world', 'rapidly', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "new_list = []\n",
        "for word in words_in_quotes:\n",
        "  if word.casefold() not in stop_words:\n",
        "    new_list.append(word)\n",
        "new_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Jv-2B_peCi_o",
        "outputId": "61c6865e-2a89-4240-cf93-2a18df343bf1"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NLP', 'models', 'transforming', 'world', 'rapidly', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# stemming"
      ],
      "metadata": {
        "id": "UADiXAcxCQro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "stemmer = PorterStemmer()\n",
        "words = word_tokenize(task)\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "stemmed_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "m0SFUL6mCVWB",
        "outputId": "e54c3ddf-1a6c-46f8-cfdd-94e3624176c4"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nlp', 'model', 'are', 'transform', 'the', 'world', 'rapidli', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk.stem import SnowballStemmer\n",
        "snowball = SnowballStemmer(language='english')\n",
        "words = word_tokenize(task)\n",
        "for word in words:\n",
        "    print(word,\"--->\",snowball.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0mofclneDoMa",
        "outputId": "5c85287c-9f2a-4008-8cf9-cf611fd2d25d"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLP ---> nlp\n",
            "models ---> model\n",
            "are ---> are\n",
            "transforming ---> transform\n",
            "the ---> the\n",
            "world ---> world\n",
            "rapidly ---> rapid\n",
            "! ---> !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import LancasterStemmer\n",
        "Lanc = LancasterStemmer()\n",
        "words = word_tokenize(task)\n",
        "for word in words:\n",
        "    print(word,\"--->\",Lanc.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7Myr1b9FDxhS",
        "outputId": "d23546d0-a788-496a-bfc5-a2198871b1eb"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLP ---> nlp\n",
            "models ---> model\n",
            "are ---> ar\n",
            "transforming ---> transform\n",
            "the ---> the\n",
            "world ---> world\n",
            "rapidly ---> rapid\n",
            "! ---> !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "regexp = RegexpStemmer('ing|e', min=4)\n",
        "words = word_tokenize(task)\n",
        "for word in words:\n",
        "    print(word,\"--->\",regexp.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MrNYLw1-EAP-",
        "outputId": "2ad473f3-eda8-4e96-d070-878bfd9a3028"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLP ---> NLP\n",
            "models ---> modls\n",
            "are ---> are\n",
            "transforming ---> transform\n",
            "the ---> the\n",
            "world ---> world\n",
            "rapidly ---> rapidly\n",
            "! ---> !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization"
      ],
      "metadata": {
        "id": "42w663v9EH6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "words = word_tokenize(task)\n",
        "for word in words:\n",
        "    print(word,\"--->\",lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "iyToGlXSEMjD",
        "outputId": "772922cc-cc09-4578-b994-49764cde4984"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLP ---> NLP\n",
            "models ---> model\n",
            "are ---> are\n",
            "transforming ---> transforming\n",
            "the ---> the\n",
            "world ---> world\n",
            "rapidly ---> rapidly\n",
            "! ---> !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# comparision"
      ],
      "metadata": {
        "id": "Xv8q8PZyEW_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer, RegexpStemmer, WordNetLemmatizer\n",
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "snowball = SnowballStemmer(language='english')\n",
        "regexp = RegexpStemmer('ing|e', min=4)\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "word_list = [\"friend\", \"friendship\", \"friends\", \"friendships\"]\n",
        "print(\"{0:20}{1:20}{2:20}{3:30}{4:40}{5:50}\".format(\"Word\",\"Porter Stemmer\",\"Snowball Stemmer\",\"Lancaster Stemmer\",'Regexp Stemmer','WordNetLemmatizer'))\n",
        "for word in word_list:\n",
        "    print(\"{0:20}{1:20}{2:20}{3:30}{4:40}{5:50}\".format(word,porter.stem(word),snowball.stem(word),lancaster.stem(word),regexp.stem(word),lemmatizer.lemmatize(word)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "D3cU14asEY1d",
        "outputId": "fd06b899-8bbc-4bb6-f227-b04c074c5fbf"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                Porter Stemmer      Snowball Stemmer    Lancaster Stemmer             Regexp Stemmer                          WordNetLemmatizer                                 \n",
            "friend              friend              friend              friend                        frind                                   friend                                            \n",
            "friendship          friendship          friendship          friend                        frindship                               friendship                                        \n",
            "friends             friend              friend              friend                        frinds                                  friend                                            \n",
            "friendships         friendship          friendship          friend                        frindships                              friendship                                        \n"
          ]
        }
      ]
    }
  ]
}